---
title: "Analysis of Ecolog plates"
author: "Fabian Roger"
date: "21 Jun 2016"
output:
  html_document:
    fig_caption: yes
    toc: yes
  pdf_document:
    latex_engine: lualatex
    toc: yes
---

In this script I import and clean the data from the 
Carbon Source Utilization Profiling using the BIOLOG™ Ecoplates



__this script imports:__ 

+ Ecolog/Biolog_reads.txt       # raw OD readings for all samples from Biolog EcoPlate
+ BOT_ID.txt                    # sample metadata
   
__this script does:__

  + quality control 
  + bias correction
  
__this script exports:__
  
  data frames:
  
  
```{r, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message=FALSE)
```

```{r load packages, echo = FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(broom)
library(minpack.lm)
library(magrittr)
library(tidyr)
library(phyloseq)
library(vegan)
library(flux)

```

The plates have the following layout:
![](EcoLogDocs/Ecoplate.jpg)   

From Graland et al 1996:

> BIOLOG plates, 96 well microtiter plates containing separate sole C sources and a redox indicator dye, produce patterns of potential C source utilization for microbial communities. 

The Ecoplates contain 31 different carbon sources in triplicates and three negative controls with the dye but no carbon source. 
The carbon sources are in the wells `B1` to `H4`, the negative control is in well `A1`. 

We incubated the plates directly with 150µl in each well and incubated them in the dark at room temperature for up to 100 hours. The plates were measured approximately every 12 hours to estimate the rate of the color development.

First, we import the data and look at it.

```{r import data}
EcoL <- read.table("Ecolog/Biolog_reads.txt", stringsAsFactors = F)
head(EcoL)

unique(EcoL$Sampling)
unique(EcoL$rep)
sort(unique(EcoL$Date))
```

`EcoL` has the following `r ncol(EcoL)` columns: `r colnames(EcoL)`

`$Date` and `$Time` give the exact time point when the plate was read and `$Sampling` represents the two independent sampling points. The `$hour` column gives the nominal time point of the reading. The `$BOT`column says from which bottle the sample was taken.

First, we merge the date and time column and transform it into POSIXct format. We
then proceed and add and `$dhour`column that gives the exact time difference
(in hours) from the first to the last reading for each plate. 

```{r check&prepare data4, echo=FALSE}
EcoL$Timepoint <- as.POSIXct( strptime( paste( EcoL$Date, EcoL$Time),"%Y-%m-%d %H:%M:%S"))

EcoL.list <- split(EcoL, list(EcoL$BOT, EcoL$Sampling))

EcoL.list <- lapply(EcoL.list, function(x) { x <-  x[with(x, order(hour)), ]
x$dhour  <- (difftime( x$Timepoint[1], x$Timepoint, units = "hours")*-1) + x$hour[1]
return(x) })

EcoL <- do.call( rbind, EcoL.list)

EcoL$dhour <- as.numeric(EcoL$dhour)

head(EcoL[ ,c("BOT", "OD700", "dhour")], 1)
tail(EcoL[ ,c("BOT", "OD700", "dhour")], 1)

```

Let's look at this information to see when the plates have been read and how long they have been incubated.

```{r check&prepare plot1, warning=FALSE, echo=FALSE}
select(EcoL, Sampling, BOT, hour, dhour) %>%
  mutate(Sampling = factor(Sampling, levels = c("Mid", "End")), dhour = as.numeric(dhour)) %>%
  distinct() %>%
  
  ggplot(aes(x = dhour, y = Sampling, colour = Sampling))+ 
    geom_point(alpha = 0.6)+
    geom_vline( aes(xintercept = hour, colour = Sampling), linetype = "dashed") +
    theme_bw(base_size = 13)+
    facet_wrap(~ Sampling, nrow = 2, scales = "free_y" )+
    labs(x = "timepoint of sampling", y = "sampling occasion", title = "distribution of readings")+
    theme(legend.position = "none")
```

We can see that the exact intervals vary  and that curiously, the total number of readings goes up to 8 per plate at the last sampling. The experimentator seemed to have gotten increasingly excited and motivated throughout the course of the experiment.

We read the plates at three different ODs. `OD590`, `OD595` & `OD700` and calculate the corrected OD readings as decribed in 

[Johansson H, Janmar L, Backhaus T. (2014) Toxicity of ciprofloxacin and sulfamethoxazole to marine periphytic algae and bacteria. PeerJ PrePrints 2:e330v1](https://doi.org/10.7287/peerj.preprints.330v1)

> Calculation of the background color development bckgd, as the median of the three
wells without any added carbon source (blanks) per plate.
Calculation of the color development (corrected absorbance, CorrOD) for each well that contained an added carbon source and for each Ecolog incubation time. This provides a measure of the total catabolic activity per carbon source and is calculated as the optical density at 595 nm (absorbance of the tetrazolium dye after oxidation) corrected for background and turbidity of the sample (absorbance at 700 nm): corrected optical density for each well as:
CorrOD =(OD595 – OD700)-bckgd

I calculate the background color development `bckgd` from the coorected blanks (OD595-OD700), too. 

```{r calculate corrected OD,  fig.height=10, fig.width=12}

# calculate the corrected OD (OD595 - OD700)
EcoL <- EcoL %>% 
  mutate(CorrOD = OD595 - OD700)

# calculate median blank for each plate at each reading
Blanks <- EcoL %>% 
  filter(Wells == "A1") %>% 
  select(Sampling, BOT, hour, CorrOD) %>% 
  group_by(Sampling, BOT, hour) %>% 
  summarise(bckgd = median(CorrOD))

# substract (corrected) background colour dev. from corrected OD
EcoL <- EcoL %>% 
  filter(Wells != "A1") %>% 
  left_join(., Blanks) %>% 
  mutate(CorrOD = CorrOD - bckgd)

# define corrected ID values < 0 as 0
EcoL[EcoL$CorrOD < 0, ]$CorrOD <- 0


EcoL %>% filter(BOT == 2, Sampling == "Mid") %>% 
  ggplot(. , aes(y= OD595, x = dhour, colour = Wells))+
  geom_line(linetype = "dashed")+
  geom_line(aes(x = hour, y = CorrOD))+
  theme_bw()+
  facet_wrap(~Wells * rep, labeller = label_wrap_gen(multi_line = FALSE), ncol = 9)+
  labs(x = "time (hours)", title = "example ecolog plate (BOT 5, sampling 06/28)\ndashed line is OD cutoff (OD = 0.2), the 3 replicates of the same carbon sources are shown in same colour ")+
  theme(legend.position = "none")
  
```


With the corrected OD vaues we will now compute two response variables. 

+ the number of positive carbon sources on each plate
+ the median uptake rate of each carbon source on each plate. 

Only those wells that show an OD development of over 0.2 are counted as
positives. Because we need the full data set to calculate the median uptake rate, we start with this:

### median uptake rate of carbon sources

To calculate the uptake rate of the carbon source, we fit a modified Gompertz
model of the form:

$$ OD = K*exp(-exp{(\frac{r*e}{K}*(l-t)+1)} $$

where 

+ $r$ is the maximum slope
+ $K$ the maximum OD and 
+ $l$ the lag phase

We then extract the $r$ parameter and take it as the **uptake rate** 

However, we only keep $r$ estimates of models that 

+ converged
+ the parameter estimate for $r$ is significant at p < 0.01

**only wells that reach an OD ≥ 0.2 are counted as *positive*. Accordingly, we attempt to model only those wells and exclude all others**

Note that I use `nlsLM` from the minpack.lm package to fit the gompertz function. It is much more efficient at fitting the wast majority of the samples than `nls`. 

I use the following starting values. 
`start = list(K = 2, l = 30, r = 0.02)`
Usually I would model all wells once and then use the median parameter estimates as new starting values but in this case the naive estimates above result in more successfull fits. 


```{r model uptake rates}

# select Wells with positive OD development
 EcoL_pos <- EcoL %>% 
  group_by(Sampling, BOT, Wells, rep) %>% 
  arrange(dhour) %>% 
  by_slice(function(x) {mean(x$CorrOD[length(x$CorrOD): length(x$CorrOD)-1]) - 
                        mean(x$CorrOD[1:2]) }, 
           .collate = "cols") %>% 
  filter(.out >= 0.01) %>% 
  inner_join(EcoL, .)


# fit function to all Wells with positive reponse
FitNls <- EcoL_pos %>%
  group_by(Sampling, BOT, Wells, rep) %>%
  do(gompertz_fit = try(nlsLM( CorrOD ~ K * exp( -exp((( r * exp( 1)) / K) * (l - dhour) + 1)),
                        data = .,
                        start = list(K = 1.28, l = 44, r = 0.03),
                        control = list(maxiter = 100)),
                        silent = T))

# try to refit wells that failed at the first attempt with gentle brootforce #

# datframe of start values
Start <- data.frame(K = rep(seq(0,3,0.2), each = 210), 
                    l = rep( rep( seq(0,120,20), each = 30), 16),
                    r = rep( seq(0.01, 0.3, 0.01), 112))

# which wells could not be fitted
EcoL_no_fit <- filter(FitNls, class(gompertz_fit) != "nls") 

# *positive* wells that were not fitted (raw data)
EcoL_pos_nf <- EcoL_pos %>% select(Sampling, BOT, Wells, rep, dhour, CorrOD) %>% 
  semi_join(., EcoL_no_fit) %>% group_by(Sampling, BOT, Wells, rep) 

# dataframe to store results
Fit <- EcoL_no_fit[0,]

# first attempt to fit wells (with differnt set of start parameters)
Fit_t <- EcoL_pos_nf %>%  do(gompertz_fit = try(nlsLM( CorrOD ~ K * exp( -exp((( r * exp( 1)) / K) * (l - dhour) + 1)),
                        data = .,
                        start = list(K = 0.5, l = 10, r = 0.02),
                        control = list(maxiter = 1024)),
                        silent = T)) %>% 
  filter(class(gompertz_fit) == "nls")

Fit <- rbind(Fit,Fit_t)

# brootforce remaining wells by looping through set of ~3000 start paramter combinations
for (i in 1: nrow(Start)) {
 Fit_t <-  anti_join(EcoL_no_fit, Fit, by=c("Sampling", "BOT", "Wells", "rep")) %>% 
  semi_join(EcoL_pos, .) %>% group_by(Sampling, BOT, Wells, rep) %>% 
    do(gompertz_fit = try(nlsLM( CorrOD ~ K * exp( -exp((( r * exp( 1)) / K) * (l - dhour) + 1)),
                        data = .,
                        start = Start[i,],
                        control = list(maxiter = 1024)),
                        silent = T)) %>% 
  filter(class(gompertz_fit) == "nls")
  
 Fit <- rbind(Fit,Fit_t)
}

FitNls <- FitNls %>% filter(class(gompertz_fit) == "nls") %>% mutate(fit = "1.trial")
Fit <- mutate(Fit, fit = "bf")

FitNls <- rbind(FitNls, Fit)


EcoL_fit <-  FitNls %>%  
  filter(class(gompertz_fit) == "nls") %>% 
  tidy(gompertz_fit) %>% 
  group_by(term) %>% 
  filter(term == "r")

```

We attempted to model `r select(EcoL_pos, Sampling, BOT, Wells, rep) %>% distinct %>% nrow` out of `r select(EcoL, Sampling, BOT, Wells, rep) %>% distinct %>% nrow` Wells and the model converged in `r filter(FitNls, fit == "1.trial") %>% nrow` at the first attempt. `r filter(FitNls, class(gompertz_fit) != "nls") %>% nrow` did not converge at all.

As rough quality control for the fits, we inspect the residuals. We calcualte the deviance as differnce in % of the mean predicted versus mean actual OD values and look at the % deviance for all models.

```{r}

FITgomp <- FitNls %>% 
  filter(class(gompertz_fit) == "nls") %>% 
  augment(gompertz_fit) %>% 
  left_join(EcoL,.) %>%  
  mutate(Sample_u = paste(Sampling, BOT))

FITgomp %>% group_by(Sampling, BOT, Wells, rep) %>% 
  summarize(meanres = mean(abs(.resid)), meanOD = mean(CorrOD)) %>% 
  mutate(dev = (meanres/meanOD)*100) %>% 
  filter(dev < 200) %>% 
  ggplot(aes(x = dev))+
  geom_histogram(binwidth = 5)+
  geom_vline(xintercept = 30, linetype = "dotted")+
  scale_x_continuous(breaks = seq(0, 180, 10))+
  labs(x = "deviance in %")

DEV <- FITgomp %>% group_by(Sampling, BOT, Wells, rep) %>% 
  summarize(meanres = mean(abs(.resid)), meanOD = mean(CorrOD)) %>% 
  mutate(dev = (meanres/meanOD)*100) %>% 
  filter(dev >= 30) %>% 
  mutate(dev = "≥30%")
```

The histogramm shows the distribution of the relative daviation of all wells. It shows that the vast majority are close fits (within ≤10%) with some clear outliers. We exclude wells that have a higher deviance than 30%.

Plots of all wells (by plate) are printed to "Ecolog/Ecolog_Plate_fit_gompertz.pdf". The colour of the best fit line (based on the predicted values from the model fit) indicates whether the well was fitted in the first attempt or later, using broot force. The shape of the points indicates whether the % deviance was above or below 30%. 

Visual inspection of the plots of all the wells show that this strategy successfully identifies very poor fits while keeping the others.

```{r,  fig.height=10, fig.width=12}

FITgomp <- left_join(FITgomp, DEV) %>% 
  mutate(dev = ifelse(is.na(dev), "<30%", "≥30%")) 

plotlist <- list()

for (i in unique(FITgomp$Sample_u)) {
    plot1 <- FITgomp %>% 
    filter(Sample_u == i) %>% 
    ggplot(., aes(x = dhour, y = CorrOD))+
    geom_point(aes(shape = dev))+
    geom_line(aes(y = .fitted, colour = ifelse(is.na(fit), "no_fit", fit)), 
              alpha = 0.8, size = 1)+
    facet_wrap(~Wells*rep,  labeller = label_wrap_gen(multi_line = FALSE), ncol = 10)+
    labs(title = i)+
    scale_colour_discrete(guide = guide_legend(title = "fitting"))
    theme_bw()
    
    plotlist[[length(plotlist)+1]] <- plot1
    
  }

#pdf("Ecolog/Ecolog_Plate_fit_gompertz.pdf")
#invisible(lapply(plotlist, print))
#dev.off()

plotlist[[34]]
```


`r nrow(FitNls)` out of `r select(EcoL_pos, Sampling, BOT, Wells, rep) %>% distinct %>% nrow` could be modeled successfully, with the help of bruteforce for `r nrow(Fit)` models.  In total `r nrow(DEV)` wells were excluded.
 
However, we also have to check the quality of the parameter estimates:

```{r inspect successfull models, fig.width=6, fig.height=6, warning=FALSE}

ggplot(EcoL_fit, aes(x= estimate))+
  geom_histogram(binwidth = 0.2)+
  theme_bw()+
  scale_y_sqrt()+
  labs(title = "histogramm of r_max, bin = 0.2\ncounts are sqrt-transformed")

ggplot(EcoL_fit, aes(x= estimate))+
  geom_histogram(binwidth = 0.01)+
  geom_histogram(data = filter(EcoL_fit, p.value <= 0.001), aes(x = estimate), binwidth = 0.01, fill = "red", alpha = 0.4)+
  theme_bw()+
  labs(title = "histogramm of all estimates falling in the interval -0.01 ≤ r ≤ 0.5 (black) and \nsignificant parameter estimates at p ≤ 0.001 (red)\nbin = 0.01, untransformed counts")+
  scale_x_continuous(limits = c(-0.01,0.5))
```

We see that the bulk of estimates is in a rather narrow range with `0 ≤ r ≤ 0.1`  but some estimators fall (way) outside this range. The significant estimators have less outliers and are more realistic. To avoid biases from outliers in the estimation of functional diversity without needing to exclude too much data, we adopt the following approach:

+ Wells that we defined as positive (see above) but were no `r` could be estimated are excluded
+ we take the unfiltered estimators and calculate the median `r` for all remaining Wells that we defined as positive
+ we truncate the estimated `r` at `0 ≤ r ≤ max(r.sig)` where `r.sig` denotes the parameter estimates of `r` with a `p.value ≤ 0.001`

This last step takes the good estimates to make a qualified guess about a realistic range of `r` values and prevents the influence of outliers.

This second step takes the good estimates to make a qualified guess about a realistic range of `r` values and prevents the influence of outliers.

According to our definition **we score those wells as positive, where the average OD at the last two measurements is at leats 0.01 higher than the average OD of the first two measurements**. 


We go back to the full data set and 

+ define the `r`for all wells with no apparent growth as 0
+ join the estimated `r` for all other wells
+ filter out the wells with a % deviance of ≥ 30%
+ truncate the very high r estimates 

```{r filter and join data}

MaxR <- filter(EcoL_fit, p.value <= 0.001) %>% #defining maximum r value after which we truncate
  summarize(., r = max(estimate))
```

`max_r` : `r MaxR`

```{r}
EcoL_r <- EcoL %>% select(Sampling, BOT, Wells, rep, Compound, Group) %>% distinct

EcoL_r <- EcoL_fit %>% ungroup %>% select(Sampling, BOT, Wells, rep, estimate) %>%  # positive wells
  rename(rmax = estimate) %>% 
  left_join(EcoL_r, .) %>% # join estimated r
  mutate(rmax = ifelse(is.na(rmax), 0, rmax)) %>% # define all wells that didn't score as positive as r = 0
  anti_join(., DEV) %>% # excluded wells that had too large deviation
  group_by(Sampling, BOT, Wells) %>% 
  summarize(rmax = median(rmax)) %>% 
  mutate(rmax = replace(rmax, rmax > MaxR$r, MaxR$r)) # truncate all estimates > MaxR at MaxR
  
  

EcoL_r %>% 
  ggplot(aes(x = rmax))+
  geom_histogram(binwidth = 0.001)+
  scale_y_sqrt()+
  labs(y = "sqrt(count)")


head(EcoL_r)
```

### Area under the curve

We also calculate the area under the curve for all wells that we succsessfully modelled (And kept after data cleaning, see above)


For that we 

+ smooth the fitted curves by predicting on hourly data, in the range 0 -124h
+ calculate the area under the curve for the predicted data, using the `auc` function from the `flux` package. between the predicted points, the function interpolates linarly and subdivides the segment in 100 sub-segments.
+ keep auc estimates for all wells for which we also kept an rmax estimate

```{r, fig.width=12, fig.height=10}

PRED <- function(x){ # defining function to predict with fitted values 
  fit <- predict(x$gompertz_fit[[1]], newdata = data.frame(dhour = seq(0,124,1)))
  DF <- data.frame(Sampling = x$Sampling,
                   BOT = x$BOT,
                   Wells = x$Wells,
                   rep = x$rep,
                   dhour = seq(0,124,1),
                   fit = fit)
  return(DF)
}

Fit.list <- anti_join(FitNls, DEV)  %>% split(1:NROW(.)) # split FitNls into list 

pred.list <- lapply(Fit.list, PRED) # predict each model with extended x-values

Fit.pred <- bind_rows(pred.list) %>% # rbind as data.frame
  mutate(Sample_u = paste(Sampling, BOT))

filter(Fit.pred, Sample_u ==  "End 25") %>% 
  ggplot()+
  geom_line(aes(x = dhour, y = fit))+
  geom_ribbon(aes(x = dhour, ymin = 0, ymax = fit), alpha = 0.4, fill = "blue")+
  geom_point(data = filter(FITgomp, Sample_u ==  "End 25"), aes(x = dhour, y = CorrOD))+
  facet_wrap(~Wells*rep,labeller = label_wrap_gen(multi_line = FALSE))+
  theme_bw()+
  labs(y = "CorrOD / fitted values", title = "Kontroll3 End - area under the curve")


# calculate area under the curve
Fit_auc <- Fit.pred %>% group_by(Sampling, BOT, Wells, rep) %>% 
  summarise(auc = auc(x = dhour, y = fit)) %>%
  group_by(Sampling, BOT, Wells) %>% 
  summarize(auc = median(auc))

#join to EcoL_r so that only Wells defined as positive there are taken into account. 
EcoL_rmax_auc <- left_join(EcoL_r, Fit_auc) 

ggplot(EcoL_rmax_auc, aes(x = auc))+
  geom_histogram()

ggplot(EcoL_rmax_auc, aes(x = auc, y =rmax))+
  geom_point(alpha = 0.4)+
  theme_bw()


filter(EcoL_rmax_auc, rmax == 0 & auc > 0) %>% 
  semi_join(EcoL, .) %>% 
  ggplot(aes(x = dhour, y = CorrOD))+
  geom_point()+
  facet_wrap(~Wells*rep*BOT)


```


export the EcoLog data

```{r}

select(EcoL, Sampling, BOT, Wells, rep, Compound, Group, dhour, CorrOD) %>% 
  left_join(EcoL_rmax_auc) %>% 
  write.table("Ecolog/EcoLog.txt", sep = "\t")

```


### calculate 

Now we need to put the data in the form of a matrix where each row is a plate and each column is a carbon source. We will take each carbon source as different *trait* with the estimated uptake rate (`r`) as *trait value*. 

For that we first create a data frame with `Sample` and `Bot` and a unique `Sample_BOT` identifier, and the estimated uptake rates

```{r prepare calculation of functional diversity}
EcoL_Func <- EcoL %>% 
  select(Sampling, BOT, Wells) %>%
  distinct() %>% 
  mutate(ID = paste(Sampling, BOT, sep = "_")) %>% 
  left_join( . , EcoL_rmax_auc ) %>% 
  mutate(r_max = replace(r_max, is.na(r_max), 0)) %>% 
  mutate(auc = replace(auc, is.na(auc), 0)) 

EcoL_Func_M_r <- 
  spread(EcoL_Func, Wells, r_max) %T>%
  {assign("RowNames", .$ID, pos = ".GlobalEnv" )} %>%  # we store the rownames seperately to be sure to not mix up our sample names
  select( -ID, -Sampling, -BOT) %>% 
  as.matrix()

rownames(EcoL_Func_M) <- RowNames
```

Let's take the chance to look at the utilization pattern on the EcoLog plates. 

```{r plot heatmap of ecolog plates, echo = FALSE, fig.width = 14, fig.height = 8}
ID <- read.table("BOT_ID.txt", colClasses = c("character")) %>%
  mutate( BOT = as.integer(BOT), ToxC = as.numeric(ToxC)) %>% 
  arrange( DIV, ToxC) %>% 
  mutate(bot_label = paste(DIV, Tox, sep = " "))

ID <- rbind(ID,ID) %>% mutate(Sampling = rep( c("Mid", "End"), each = nrow(ID)))

rownames(ID) <- paste(ID$Sampling, ID$BOT, sep="_")

WellID <- read.table("EcoLog/Compounds.txt", header=T, stringsAsFactors = FALSE) %>% 
  arrange( Group) %>% 
  mutate(Well_label = paste(Compound, Group, sep = " | "))

rownames(WellID) <- WellID$Wells

Ecolog_phylo <- phyloseq(otu_table(EcoL_Func_M, taxa_are_rows = FALSE),
                         sample_data(ID),
                         tax_table(as.matrix(WellID)))

sample_data(Ecolog_phylo)$Sampling <- factor(sample_data(Ecolog_phylo)$Sampling, levels = c("Mid", "End"))

C_heat <- plot_heatmap(Ecolog_phylo,
             sample.label = "bot_label",
             sample.order = rownames(ID),
             taxa.label = "Well_label",
             taxa.order = rownames(WellID))+
  theme_bw(base_size = 11)+
  theme(axis.text.x = element_text(angle = -90, hjust = 0, vjust = 0.5),
        legend.position = "bottom")+
    facet_wrap( ~ Sampling, scales = "free_x", ncol = 3)+
  ggtitle("carbon source utilization pattern")

C_heat
  
```

Now we calculate functional diversity of the samples. For that we will consider each carbon source as trait and the uptake rate as trait value. However, as we don't have information about which species have which traits we cannot compute trait diversity as it is usually done. 

We choose another approach which is equivalent to the way we calculate species richness, i.e. the effective number of traits in the community. For that we will calculate the Shannon entropy of traits in each sample, taking the uptake rate as "relative abundance". We will then convert the entropy to an effective number. 

In our case the minimum value is 0 (no carbon source is metabolized) and the maximum value is 31 (all carbon sources are metabolized evenly).

```{r calculate functional diveristy}
FunDiv <- diversity(EcoL_Func_M) %>% 
  exp() %>%
  data.frame(FuncDiv = .) %>% 
  add_rownames(var = "ID") %>% 
  mutate(Sampling = substr(ID, 1,3)) %>% 
  mutate(BOT = as.integer(sub(".+_(\\d+)", "\\1", ID))) %>%
  left_join(., ID) %>% 
  mutate(Sampling = factor(Sampling, levels = c("Mid", "End")))
``` 

We clean the data frame and export the Functional diversity data.

```{r write data}
FunDiv <- select(FunDiv, Sampling, BOT, DIV, Tox, ToxC, FuncDiv)

write.table(FunDiv, "Ecolog/FunDiv.txt", sep = "\t")

```

Finally, let's also have a quick look at the Functional diversity values that we calculated, by Lake and Sampling. 

```{r plot functional diversity, echo = FALSE, fig.width= 10, fig.height=8}
  ggplot(FunDiv, aes(x = DIV, y = FuncDiv, colour = Tox, shape = Sampling))+
    geom_point(position = position_dodge(width = 0.4))+
   # facet_wrap(~Sampling,  labeller = label_wrap_gen(multi_line = FALSE))+
    theme_bw()+
    theme(axis.text.x = element_text(angle = -90, hjust = 0, vjust = 0.5),
        legend.position = "none")+
    #scale_colour_manual(values = c("orange", "darkred", "darkgreen", "darkblue"  ))+
    labs( y = "effective number of traits", x = "dilution factor", title = "functional diversity")
  
```


### Comparing Model fit to Weibull model as in [REF](https://peerj.com/preprints/330v1/)

Weibull model: $$ CorrOD = 1-exp(-exp(A+B*log(dhour, base = 10))) $$ 

The results of both model fits are plotted together with the raw data as **Plate_fit.pdf**. 

Below is one example, for plate 1 on the "mid" sampling. The Weibull model fit is shown in red, the Gompertz model fit in blue. 

This example (and the plots for all other plates) show that in the majority of the cases, the Gompertz model fits the data more closely than the Weibull model. 

The problem is that (as specified) the Weibull model has a hardcoded upper limit of `CorrOD` = 1. Changing this number or adding a third paramter instead, imporves the residual distribution but decreases the number of Wells that can't be modelled. 

As the gompertz model fits the data closely and successfully models the vast majority of wells, I stick with it.


```{r}
# fit function to all Wells with positive reponse (start paramters are median parameters from first fit round)
FitWeib <- EcoL0.2 %>%
  group_by(Sampling, BOT, Wells, rep) %>%
  do(weibull_fit = try(nlsLM( CorrOD ~ 1 - exp(-exp(A+B*log(dhour,10))),
                        data = .,
                        start = list(A = -21.6, B = 13),
                        control = list(maxiter = 100)),
                        silent = T))

#compare to previous model fits
FitNls.pre <- filter(FitNls, class(gompertz_fit) != "try-error") %>% 
    augment(gompertz_fit)  
            
#newdata <- filter(FitNls, class(gompertz_fit) != "try-error") %>% expand(Sampling, BOT, Wells, rep, dhour=seq(1,62, 124))

# predict
FitNls.pre <- FitNls.pre %>% rename(fit_nls = .fitted, res_nls = .resid)

#predict Weibull and join raw data + prvoups predicted model fits
FITCOMP <- filter(FitWeib, class(weibull_fit) != "try-error") %>% 
  augment(weibull_fit) %>% 
  left_join(EcoL, .) %>% 
  left_join(FitNls.pre)

#plot as multipage pdf

plotlist <- list()

for (i in unique(FITCOMP$BOT)) {
  for (n in c("Mid", "End")) {
    plot1 <- FITCOMP %>% 
    filter(BOT ==i, Sampling == n) %>% 
    ggplot(., aes(x = dhour, y = CorrOD))+
    geom_point(colour = "grey")+
    geom_line(aes(x = dhour, y = .fitted), colour = "red", 
              alpha = 0.8, size = 1)+
    geom_line(aes(x = dhour, y = fit_nls), colour = "blue",
              alpha = 0.6, size = 1)+
    facet_wrap(~ Wells*rep,  labeller = label_wrap_gen(multi_line = FALSE), ncol = 9)+
    labs(title = paste(paste("Bottle -", i), paste("Sampling -", n)))+
    theme_bw()
    
    plotlist[[length(plotlist)+1]] <- plot1
    
  }}

pdf("Plate_fit.pdf")
invisible(lapply(plotlist, print))
dev.off()
  

#plot an example here

  FITCOMP %>% 
    filter(BOT ==1, Sampling == "Mid") %>% 
    ggplot(., aes(x = dhour, y = CorrOD))+
    geom_point(colour = "grey")+
    geom_line(aes(x = dhour, y = .fitted), colour = "red", 
              alpha = 0.8, size = 1)+
    geom_line(aes(x = dhour, y = fit_nls), colour = "blue",
              alpha = 0.6, size = 1)+
    facet_wrap(~ Wells*rep,  labeller = label_wrap_gen(multi_line = FALSE), ncol = 9)+
    labs(title = "BOT - 1, Sampling - Mid")+
    theme_bw()

  
# compare residuals
  FITCOMP %>% 
    select(BOT, .resid, res_nls) %>% 
    gather(model, residuals, -BOT) %>% 
    mutate(model = ifelse(model == ".resid", "Weibull", "Gompertz")) %>% 
  ggplot(., aes(x = residuals))+
    geom_histogram(binwidth = 0.01)+
    facet_wrap(~model)+
    labs(title = "residuals distributions")

```



